{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习工程师纳米学位（试学班）\n",
    "## 项目 0: 预测你的下一道世界料理\n",
    "\n",
    "\n",
    "欢迎来到机器学习的预测烹饪菜系项目！在此文件中，有些示例代码已经提供给你，但你还需要实现更多的功能来让项目成功运行。除非有明确要求，你无须修改任何已给出的代码。以**编程练习**开始的标题表示接下来的内容中有需要你必须实现的功能。每一部分都会有详细的指导，需要实现的部分也会在注释中以**TODO**标出。请仔细阅读所有的提示！\n",
    "\n",
    ">**提示：**Code 和 Markdown 区域可通过 **Shift + Enter** 快捷键运行。此外，Markdown可以通过双击进入编辑模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第一步. 下载并导入数据\n",
    "在这个项目中，你将利用[Yummly](https://www.yummly.com/)所提供的数据集来训练和测试一个模型，并对模型的性能和预测能力进行测试。通过该数据训练后的好的模型可以被用来对菜系进行预测。\n",
    "\n",
    "此项目的数据集来自[Kaggle What's Cooking 竞赛](https://www.kaggle.com/c/whats-cooking/data)。共 39774/9944 个训练和测试数据点，涵盖了中国菜、越南菜、法国菜等的信息。数据集包含以下特征：\n",
    "- 'id'：24717, 数据编号\n",
    "- 'cuisine'：\"indian\", 菜系\n",
    "- 'ingredients'：[\"tumeric\", \"vegetable stock\", ...] 此菜所包含的佐料\n",
    "\n",
    "首先你需要前往此 [菜系数据集](https://www.kaggle.com/c/whats-cooking/data) 下载(选择 **Download All** )。如果不能正常下载，请参考教室中的下载教程。然后运行下面区域的代码以载入数据集，以及一些此项目所需的 Python 库。如果成功返回数据集的大小，表示数据集已载入成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 配置环境\n",
    "首先按快捷键 `ctrl+R` 输入 `cmd` 打开我们的终端，然后输入以下代码，安装本实验所需要的库函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# 安装项目所需要的库\n",
    "# 注意该代码不能在此直接运行\n",
    "pip install pandas numpy nltk matplotlib\n",
    "python -c \"import nltk;nltk.download('popular')\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 加载数据 \n",
    "其次，在下载完实验数据集后，我们将其解压至当前目录中(即：`MLND-cn-trial\\`目录下面)， 然后依次输入以下代码，加载本次实验的训练集和测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "# 导入依赖库\n",
    "import json\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 加载数据集\n",
    "train_filename='train.json'\n",
    "train_content = pd.read_json(codecs.open(train_filename, mode='r', encoding='utf-8'))\n",
    "\n",
    "test_filename = 'test.json'\n",
    "test_content = pd.read_json(codecs.open(test_filename, mode='r', encoding='utf-8'))\n",
    "    \n",
    "# 打印加载的数据集数量\n",
    "print(\"菜名数据集一共包含 {} 训练数据 和 {} 测试样例。\\n\".format(len(train_content), len(test_content)))\n",
    "if len(train_content)==39774 and len(test_content)==9944:\n",
    "    print(\"数据成功载入！\")\n",
    "else:\n",
    "    print(\"数据载入有问题，请检查文件路径！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 数据预览\n",
    "为了查看我们的数据集的分布和菜品总共的种类，我们打印出部分数据样例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "pd.set_option('display.max_colwidth',120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习\n",
    "你需要通过`head()`函数来预览训练集`train_content`数据。（输出前5条）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO：打印train_content中前5个数据样例以预览数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "## 查看总共菜品分类\n",
    "categories=np.unique(train_content['cuisine'])\n",
    "print(\"一共包含 {} 种菜品，分别是:\\n{}\".format(len(categories),categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第二步. 分析数据\n",
    "在项目的第二个部分，你会对菜肴数据进行初步的观察并给出你的分析。通过对数据的探索来熟悉数据可以让你更好地理解和解释你的结果。\n",
    "\n",
    "由于这个项目的最终目标是建立一个预测世界菜系的模型，我们需要将数据集分为**特征(Features)**和**目标变量(Target Variables)**。\n",
    "- **特征**: `'ingredients'`，给我们提供了每个菜品所包含的佐料名称。\n",
    "- **目标变量**：` 'cuisine'`，是我们希望预测的菜系分类。\n",
    "\n",
    "他们分别被存在 `train_ingredients` 和 `train_targets` 两个变量名中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习：数据提取\n",
    "* 将`train_content`中的`ingredients`赋值到`train_integredients`\n",
    "* 将`train_content`中的`cuisine`赋值到`train_targets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### TODO：将特征与目标变量分别赋值\n",
    "train_ingredients = None\n",
    "train_targets = None\n",
    "\n",
    "### TODO: 打印结果，检查是否正确赋值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习：基础统计运算\n",
    "你的第一个编程练习是计算有关菜系佐料的统计数据。我们已为你导入了 `numpy`，你需要使用这个库来执行必要的计算。这些统计数据对于分析模型的预测结果非常重要的。\n",
    "在下面的代码中，你要做的是：\n",
    "- 使用最频繁的佐料前10分别有哪些？\n",
    "- 意大利菜中最常见的10个佐料有哪些？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: 统计佐料出现次数，并赋值到sum_ingredients字典中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "# Finally, plot the 10 most used ingredients\n",
    "plt.style.use(u'ggplot')\n",
    "fig = pd.DataFrame(sum_ingredients, index=[0]).transpose()[0].sort_values(ascending=False, inplace=False)[:10].plot(kind='barh')\n",
    "fig.invert_yaxis()\n",
    "fig = fig.get_figure()\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: 统计意大利菜系中佐料出现次数，并赋值到italian_ingredients字典中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "# Finally, plot the 10 most used ingredients\n",
    "fig = pd.DataFrame(sum_ingredients, index=[0]).transpose()[0].sort_values(ascending=False, inplace=False)[:10].plot(kind='barh')\n",
    "fig.invert_yaxis()\n",
    "fig = fig.get_figure()\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第三步. 建立模型\n",
    "在项目的第三步中，你需要了解必要的工具和技巧来让你的模型进行预测。用这些工具和技巧对每一个模型的表现做精确的衡量可以极大地增强你预测的信心。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 单词清洗\n",
    "由于菜品包含的佐料众多，同一种佐料也可能有单复数、时态等变化，为了去除这类差异，我们考虑将**ingredients** 进行过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "\n",
    "def text_clean(ingredients):\n",
    "    #去除单词的标点符号，只保留 a..z A...Z的单词字符\n",
    "    ingredients= np.array(ingredients).tolist()\n",
    "    print(\"菜品佐料：\\n{}\".format(ingredients[9]))\n",
    "    ingredients=[[re.sub('[^A-Za-z]', ' ', word) for word in component]for component in ingredients]\n",
    "    print(\"去除标点符号之后的结果：\\n{}\".format(ingredients[9]))\n",
    "\n",
    "    # 去除单词的单复数，时态，只保留单词的词干\n",
    "    lemma=WordNetLemmatizer()\n",
    "    ingredients=[\" \".join([ \" \".join([lemma.lemmatize(w) for w in words.split(\" \")]) for words in component])  for component in ingredients]\n",
    "    print(\"去除时态和单复数之后的结果：\\n{}\".format(ingredients[9]))\n",
    "    return ingredients\n",
    "\n",
    "print(\"\\n处理训练集...\")\n",
    "train_ingredients = text_clean(train_content['ingredients'])\n",
    "print(\"\\n处理测试集...\")\n",
    "test_ingredients = text_clean(test_content['ingredients'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 特征提取\n",
    "在该步骤中，我们将菜品的佐料转换成数值特征向量。考虑到绝大多数菜中都包含`salt, water, sugar, butter`等，采用one-hot的方法提取的向量将不能很好的对菜系作出区分。我们将考虑按照佐料出现的次数对佐料做一定的加权，即：佐料出现次数越多，佐料的区分性就越低。我们采用的特征为TF-IDF，相关介绍内容可以参考：[TF-IDF与余弦相似性的应用（一）：自动提取关键词](http://www.ruanyifeng.com/blog/2013/03/tf-idf.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 将佐料转换成特征向量\n",
    "\n",
    "# 处理 训练集\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 1),\n",
    "                analyzer='word', max_df=.57, binary=False,\n",
    "                token_pattern=r\"\\w+\",sublinear_tf=False)\n",
    "train_tfidf = vectorizer.fit_transform(train_ingredients).todense()\n",
    "\n",
    "## 处理 测试集\n",
    "test_tfidf = vectorizer.transform(test_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "train_targets=np.array(train_content['cuisine']).tolist()\n",
    "train_targets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 验证集划分\n",
    "为了在实验中大致估计模型的精确度我们将从原本的`train_ingredients` 划分出 `20%` 的数据用作`valid_ingredients`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习：数据分割与重排\n",
    "调用`train_test_split`函数将训练集划分为新的训练集和验证集，便于之后的模型精度观测。\n",
    "* 从`sklearn.model_selection`中导入`train_test_split`\n",
    "* 将`train_tfidf`和`train_targets`作为`train_test_split`的输入变量\n",
    "* 设置`test_size`为0.2，划分出20%的验证集，80%的数据留作新的训练集。\n",
    "* 设置`random_state`随机种子，以确保每一次运行都可以得到相同划分的结果。（随机种子固定，生成的随机序列就是确定的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO：划分出验证集\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 建立模型 \n",
    "调用 `sklearn` 中的逻辑回归模型（Logistic Regression）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习：训练模型\n",
    "* 从`sklearn.linear_model`导入`LogisticRegression`\n",
    "* 从`sklearn.model_selection`导入`GridSearchCV`, 参数自动搜索，只要把参数输进去，就能给出最优的结果和参数，这个方法适合小数据集。\n",
    "* 定义`parameters`变量：为`C`参数创造一个字典，它的值是从1至10的数组;\n",
    "* 定义`classifier`变量: 使用导入的`LogisticRegression`创建一个分类函数;\n",
    "* 定义`grid`变量: 使用导入的`GridSearchCV`创建一个网格搜索对象；将变量'classifier', 'parameters'作为参数传至这个对象构造函数中；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## TODO: 建立逻辑回归模型\n",
    "parameters = None\n",
    "\n",
    "classifier = None\n",
    "\n",
    "grid = None\n",
    "\n",
    "\n",
    "## 请不要修改下方代码\n",
    "grid = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练结束之后，我们计算模型在验证集`X_valid`上预测结果，并计算模型的预测精度（与`y_valid`逐个比较）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "valid_predict = grid.predict(X_valid)\n",
    "valid_score=accuracy_score(y_valid,valid_predict)\n",
    "\n",
    "print(\"验证集上的得分为：{}\".format(valid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第四步. 模型预测（可选）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 预测测试集\n",
    "\n",
    "### 编程练习\n",
    "* 将模型`grid`对测试集`test_tfidf`做预测，然后查看预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO：预测测试结果\n",
    "predictions = None\n",
    "\n",
    "## 请不要修改下方代码\n",
    "print(\"预测的测试集个数为：{}\".format(len(predictions)))\n",
    "test_content['cuisine']=predictions\n",
    "test_content.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 提交结果\n",
    "为了更好的测试模型的效果，同时比较与其他人的差距，我们将模型的测试集上的结果提交至 [kaggle whats cooking](https://www.kaggle.com/c/whats-cooking/submit) （需要提前注册kaggle账号）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载结果格式\n",
    "submit_frame = pd.read_csv(\"sample_submission.csv\")\n",
    "## 保存结果\n",
    "result = pd.merge(submit_frame, test_content, on=\"id\", how='left')\n",
    "result = result.rename(index=str, columns={\"cuisine_y\": \"cuisine\"})\n",
    "test_result_name = \"tfidf_cuisine_test.csv\"\n",
    "result[['id','cuisine']].to_csv(test_result_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将生成的 **tfidf_cuisine_test.csv** 提交至 <https://www.kaggle.com/c/whats-cooking/submit> 然后选择 **Upload Submission File**, 点击 **Make submission**即可。稍作等待，就可以看到右上角的评分结果（得分大致为：`0.78580` 左右）。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
